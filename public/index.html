<html>
<head>
  <script src="/js/face-api.min.js"></script>
  <script src="/js/faceDetectionControls.js"></script>
  <style>
    #overlay, .overlay {
     position: absolute;
     top: 0;
     left: 0;
     width: 500px;
	height: 375px;
    }
#container {
	margin: 0px auto;
	width: 500px;
	height: 375px;
	border: 10px #333 solid;
}
#videoElement {
	width: 500px;
	height: 375px;
	background-color: #666;
}
  </style>
</head>
 
<body>
 
  <div style="position: relative" class="margin">
	<video autoplay="true" id="videoElement">
	</video>
  <canvas id="overlay" />
  </div>

  
    

  <script>
    var video = document.querySelector("#videoElement");
    let withBoxes = true
    let withFaceLandmarks = true
    var labeledFaceDescriptors;

    if (navigator.mediaDevices.getUserMedia) {
      navigator.mediaDevices.getUserMedia({ video: true })
        .then(function (stream) {
          video.srcObject = stream;
        })
        .catch(function (err0r) {
          console.log("Something went wrong!");
        });
    }

    async function onPlay(videoEl) {
      if(!videoEl.currentTime || videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
        return setTimeout(() => onPlay(videoEl))
      const options = getFaceDetectorOptions()
      const ts = Date.now()
      const drawBoxes = withBoxes
      const drawLandmarks = withFaceLandmarks
      let task = faceapi.detectAllFaces(videoEl, options)
     
      task = withFaceLandmarks ? task.withFaceLandmarks().withFaceDescriptors() : task
      
      const results = await task
      //let fullFaceDescriptions = task.withFaceDescriptors()
      //updateTimeStats(Date.now() - ts)
      const canvas = document.getElementById('overlay')
      //faceapi.matchDimensions(canvas, videoEl)
      const dims = faceapi.matchDimensions(canvas, videoEl, true)
      const resizedResults = faceapi.resizeResults(results, dims)
      
      if (drawBoxes) {
        faceapi.draw.drawDetections(canvas, resizedResults)
      }
      if (drawLandmarks) {
        faceapi.draw.drawFaceLandmarks(canvas, resizedResults)
      }
      
      //faceapi.draw.drawDetections(canvas, results)
      //faceapi.draw.drawFaceLandmarks(canvas, results)

      const maxDescriptorDistance = 0.6
      const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, maxDescriptorDistance)
      const resultsD = results.map(fd => faceMatcher.findBestMatch(fd.descriptor))

      resultsD.forEach((bestMatch, i) => {
        const box = results[i].detection.box
        const text = bestMatch.toString()
         console.log(text)
        const drawBox = new faceapi.draw.DrawBox(box, { label: text })
        drawBox.draw(canvas)
      })
      setTimeout(() => onPlay(videoEl))
    }

    
    
    async function loadModels() {
      const MODEL_URL = '/models'
      await faceapi.loadSsdMobilenetv1Model(MODEL_URL)
      await faceapi.loadFaceLandmarkModel(MODEL_URL)
      await faceapi.loadFaceRecognitionModel(MODEL_URL)
     
      const labels = ['tanakit','Poonunuch','sorayas']
      labeledFaceDescriptors = await Promise.all(
        labels.map(async label => {
        const imgUrl = `/pics/${label}.jpg`
        const img = await faceapi.fetchImage(imgUrl)
        const fullFaceDescription = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor()
        if (!fullFaceDescription) {
          throw new Error(`no faces detected for ${label}`)
        }
        const faceDescriptors = [fullFaceDescription.descriptor]
        return new faceapi.LabeledFaceDescriptors(label, faceDescriptors)
        })
      )
      onPlay(video)
      /*
      // 0.6 is a good distance threshold value to judge
      // whether the descriptors match or not
      const maxDescriptorDistance = 0.6
      const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, maxDescriptorDistance)
      const results = fullFaceDescriptions.map(fd => faceMatcher.findBestMatch(fd.descriptor))

      results.forEach((bestMatch, i) => {
        const box = fullFaceDescriptions[i].detection.box
        const text = bestMatch.toString()
         console.log(text)
        const drawBox = new faceapi.draw.DrawBox(box, { label: text })
        drawBox.draw(canvas)
      })
      */
    }
    loadModels()

  </script>

</body>
</html>
